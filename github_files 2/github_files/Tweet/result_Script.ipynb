{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d968edf-743d-4de1-ac77-5638a8b46ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-12-12 13:26:42--  https://ciir.cs.umass.edu/downloads/LaMP/LaMP_7/train/train_outputs.json\n",
      "Resolving ciir.cs.umass.edu (ciir.cs.umass.edu)... 128.119.246.154\n",
      "Connecting to ciir.cs.umass.edu (ciir.cs.umass.edu)|128.119.246.154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1308585 (1.2M) [application/json]\n",
      "Saving to: ‘train_outputs.json’\n",
      "\n",
      "train_outputs.json  100%[===================>]   1.25M  4.72MB/s    in 0.3s    \n",
      "\n",
      "2023-12-12 13:26:42 (4.72 MB/s) - ‘train_outputs.json’ saved [1308585/1308585]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://ciir.cs.umass.edu/downloads/LaMP/LaMP_7/train/train_outputs.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b832b0d-c790-4fd9-955d-c4b0cdfba49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge-score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting absl-py (from rouge-score)\n",
      "  Downloading absl_py-2.0.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: nltk in /Users/deeparm/anaconda3/envs/ir_project/lib/python3.8/site-packages (from rouge-score) (3.8.1)\n",
      "Requirement already satisfied: numpy in /Users/deeparm/anaconda3/envs/ir_project/lib/python3.8/site-packages (from rouge-score) (1.24.3)\n",
      "Requirement already satisfied: six>=1.14.0 in /Users/deeparm/anaconda3/envs/ir_project/lib/python3.8/site-packages (from rouge-score) (1.16.0)\n",
      "Requirement already satisfied: click in /Users/deeparm/anaconda3/envs/ir_project/lib/python3.8/site-packages (from nltk->rouge-score) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/deeparm/anaconda3/envs/ir_project/lib/python3.8/site-packages (from nltk->rouge-score) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/deeparm/anaconda3/envs/ir_project/lib/python3.8/site-packages (from nltk->rouge-score) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in /Users/deeparm/anaconda3/envs/ir_project/lib/python3.8/site-packages (from nltk->rouge-score) (4.66.1)\n",
      "Downloading absl_py-2.0.0-py3-none-any.whl (130 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: rouge-score\n",
      "  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24932 sha256=33740223b78e6f914f4131e13c3b86b4636fc5614471102a42b64f2afb63ab2e\n",
      "  Stored in directory: /Users/deeparm/Library/Caches/pip/wheels/24/55/6f/ebfc4cb176d1c9665da4e306e1705496206d08215c1acd9dde\n",
      "Successfully built rouge-score\n",
      "Installing collected packages: absl-py, rouge-score\n",
      "Successfully installed absl-py-2.0.0 rouge-score-0.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e04321e7-6cc7-469c-8243-225e6417e094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twitter set\n",
      "ROUGE-1: Precision = 0.2821300446541186, Recall = 0.28517548735957954, F1 = 0.2724162745451939\n",
      "ROUGE-L: Precision = 0.2548903040222507, Recall = 0.2581007809618956, F1 = 0.24682899676902625\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from rouge import Rouge\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
    "# Specify the path to your JSON file\n",
    "json_file_path = \"train_outputs.json\"\n",
    "json_file_path_llm = \"output_tweet_llm_output.json\"\n",
    "\n",
    "# Read the JSON file\n",
    "with open(json_file_path, \"r\") as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "with open(json_file_path_llm, \"r\") as json_file:\n",
    "    data_llm_out = json.load(json_file)\n",
    "\n",
    "# Now 'data' contains the content of the JSON file as a Python dictionary\n",
    "precision = {'r1':[], 'rl':[]}\n",
    "recall = {'r1':[], 'rl':[]}\n",
    "f1score = {'r1':[], 'rl':[]}\n",
    "for idx, i in enumerate(data['golds'][:100]):\n",
    "    ref = i['output']\n",
    "    pred = data_llm_out['llm_output'][idx]\n",
    "    scores = scorer.score(ref, pred)\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
    "    recall['r1'].append(scores['rouge1'].recall)\n",
    "    precision['r1'].append(scores['rouge1'].precision)\n",
    "    f1score['r1'].append(scores['rouge1'].fmeasure)\n",
    "\n",
    "    recall['rl'].append(scores['rougeL'].recall)\n",
    "    precision['rl'].append(scores['rougeL'].precision)\n",
    "    f1score['rl'].append(scores['rougeL'].fmeasure)\n",
    "    \n",
    "print(\"Twitter set\")\n",
    "print(f\"ROUGE-1: Precision = {np.mean(precision['r1'])}, Recall = {np.mean(recall['r1'])}, F1 = {np.mean(f1score['r1'])}\")\n",
    "print(f\"ROUGE-L: Precision = {np.mean(precision['rl'])}, Recall = {np.mean(recall['rl'])}, F1 = {np.mean(f1score['rl'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ad48b62-2797-4bac-980c-5788e74443b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2724162745451939"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.mean(f1score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8159550-0808-4fcf-9ab7-ff16d4af4d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# Sample reference and hypothesis summaries\n",
    "reference = \"The quick brown fox jumps over the lazy dog.\"\n",
    "hypothesis = \"A fast brown fox jumps over a lazy canine.\"\n",
    "\n",
    "# Initialize the Rouge object\n",
    "# rouge = Rouge()\n",
    "\n",
    "# Compute ROUGE scores\n",
    "scores = scorer.score(reference, hypothesis)\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df5088e5-6dbd-4794-91de-6315b1599889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE Scores:\n",
      "ROUGE-1: Precision = 0.5555555555555556, Recall = 0.5555555555555556, F1 = 0.5555555555555556\n",
      "ROUGE-2: Precision = 0.375, Recall = 0.375, F1 = 0.375\n",
      "ROUGE-L: Precision = 0.5555555555555556, Recall = 0.5555555555555556, F1 = 0.5555555555555556\n"
     ]
    }
   ],
   "source": [
    "print(\"ROUGE Scores:\")\n",
    "print(f\"ROUGE-1: Precision = {scores['rouge1'].precision}, Recall = {scores['rouge1'].recall}, F1 = {scores['rouge1'].fmeasure}\")\n",
    "print(f\"ROUGE-2: Precision = {scores['rouge2'].precision}, Recall = {scores['rouge2'].recall}, F1 = {scores['rouge2'].fmeasure}\")\n",
    "print(f\"ROUGE-L: Precision = {scores['rougeL'].precision}, Recall = {scores['rougeL'].recall}, F1 = {scores['rougeL'].fmeasure}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
